\documentclass[a4paper,12pt]{report}

% The following makes latex use nicer postscript fonts.
\usepackage{times}
\usepackage[english]{babel}
\usepackage[unicode=true]{hyperref}
\usepackage[grey,utopia]{quotchap}
\usepackage{booktabs}
\usepackage{vubtitlepage}
\usepackage{listings}
\usepackage{color}
\usepackage[bottom]{footmisc}

% Code listings costumization
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codeblue}{rgb}{0,0,0.85}
\definecolor{codedarkblue}{rgb}{0,0,0.5}
\definecolor{codered}{rgb}{0.85,0,0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    stringstyle=\color{codered},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle, escapeinside={<@}{@>}}


\author{Vincent De Schutter}
\title{Preparatory: Automagically shared and \\offline available data for the web}

%\promotortitle{Promotor/Promotors}
\promotor{Prof. Dr. Wolfgang De Meuter}
\advisors{Tim Coppieters}
\advisortitle{Begeleider}
\faculty{Faculteit Wetenschappen en Bio-ingenieurswetenschappen}
\department{Vakgroep Computerwetenschappen}
\reason{Voorbereiding voor Proefschrift ingediend met het oog op het behalen \\van de graad van 
Bachelor of Science in de computerwetenschappen}
\date{Februari 2015}
          
\begin{document}

% First dutch TitlePage
%\maketitlepage

\faculty{Faculty of Science and Bio-Engineering Sciences}
\advisortitle{Advisor}
\department{Department of Computer Science}
\reason{Preparatory to Bachelor Thesis submitted in partial fulfillment of the \\
requirements for the degree of Bachelor of Science in Computer Science}

\date{February 2015}

% Then english TitlePage
\maketitlepage

\tableofcontents
\newpage

\chapter{Introduction}\label{cha:Introduction} % 1
%TODO
\chapter{Context}\label{cha:Context} % 5

%TODO
This chapter includes an introduction to the main concepts of eventual consistency. 

\section{Eventual Consistency}\label{sec:EventualConsistency}

One of the most important aspects of distributed systems is data replication. This phenomenon is used in a wide range of applications, such as databases, caches, and many more. In this case, data replication will consists out of maintaining multiple copies of data on different computers. Those copies, often called replicas, improve the availability, performance and safety of the distributed system. \\
When one of the replicas is offline, availability is achieved by allowing access to the data through another replica. This also offers applications to work offline, which is one of the key subjects of this paper. \\
If the data is replicated across multiple computers, also called sites, the user can reduce the latency by choosing the nearest site. Besides that, different requests can be handled concurrently which reduces the load on a specific site. \\
Another benefit of data replication is safety. If replicas are considered as backups, safety is attained. For example, when one of the replicas experiences a deadly crash, the data is not lost because it can still be acquired from another site.\\
\newline
When talking about data replication, there are roughly two types to distinguish. The first one is called traditional or pessimistic replication. This is a more strong technique that focuses on consistent data at the expense of availability. If the data needs to be more available but may differ a little, optimistic replication is a better solution.

\subsection{Pessimistic Replication}\label{sec:PessimisticReplication}

The main purpose of pessimistic replication is trying to maintain one single consistent state of the data on all the different sites. This can be achieved by allowing updates to a specific piece of data only when it is consistent with all other replications. If some data is not up to date, it will be locked until it's consistent. Hence the name "pessimistic". This technique is also known as strong consistency due the fact that there is only one single view of the data and therefore all the replicas are consistent. Pessimistic replication is used in a wide range of applications and algorithms. For example, primary-copy algorithms, elect a primary replica that is responsible for handling all access to a specific object. If the primary replica receives an update of this object, it will be propagated synchronously to all secondary replicas. In case the primary replica crashes, the other replicas agree to assign another primary replica. A drawback of this technique is the deployment on a wide-area network for two reasons. \\
\indent First, replicas could be unavailable for too long due the slowness en unreliability of the Internet. This causes even more problems with the raise of mobile devices with intermittent connectivity. Synchronizing with an unavailable replica, would block the device indefinitely. \\
\indent The second reason relates to scalability towards wide-area networks. Applications with pessimistic replication on larger networks often have more users and replicas. The more users, the more updates will occur, the more time the replicas need to wait to send the updates to the other replicas. \\
Because of this two reasons pessimistic replication is mainly used in local-area applications. A major part uses optimistic replication instead.

\subsection{Optimistic Replication}\label{sec:OptimisticReplication}

When replicated data needs to be shared efficiently in a wide-area network, optimistic replication is a preferable solution. The key difference between optimistic and pessimistic replication is the possibility to access and update replicas synchronously without locking the data. However this feature gives rise to new conflicts. If a piece of data is not locked, two or more operations can concurrently adjust the piece of data. This leads to inconsistent data and thus inconsistent replicas. The optimistic part of this algorithm is the assumption that these concurrent operations occur sporadically or will be easy to resolve. However, the impact of the concurrent operations depends on the application. \\
\indent For example, when two users perform an operation on the same piece of date independently. The first user updates the data while the seconds user removes the data. Will the data been removed or been updated when the two operations are merged? The first one, often called 'lost-updates', causes the first user to lose his updates. The second possibility will undo the removal of the second user. This won't seem that complicated, however what will happen if three or more users perform an operation on the same piece of data? \\
It is the role of consistency models to ensure that all the replicas, who have the possibility to temporarily differ from each other, converge to one single consistent state. Thus the replicas will be eventual consistent. Hence, optimistic replication is often referred as eventual consistency. Due the high availability of eventual consistent applications, the data can be, without first synchronizing, accessed and updated concurrently. This feature makes it possible to work with an unreliable or even without a connection. \\

\subsection{Elements of Eventual Consistency}\label{sec:Elements}

When talking about eventual consistency, there are a few important basic concepts one needs to know. These terms are also widely used throughout this paper and the actual paper about eventual consistency. 
\newline

\begin{table}
    \small
	\centering
    \begin{tabular}{l|p{9,5cm}}
    	\toprule
   		Term & Meaning \\
    	\midrule
    	Site & A single computer which stores a copy of replicated data in a replicated system is called a site. \\
    	Object & A notion of the minimal data unit in a replicated system. \\
    	Replica & A copy of a particular object on a particular site. \\
        Operation & A local update performed on one of the replicas. \\
        Tentative operation & Local operations that are not yet part of the final order of the system. \\
        Operation-transfer & Eventual consistency system where operations are described more semantically. \\
        State-transfer & Eventual consistency system where operations are limited to overwrite entire objects. \\
        Log & A list of recent operations stored on each site. \\
        Conflict & The phenomenon when multiple users perform concurrent updates to the same object. \\
        Propagation & The process responsible for sending operations to the other sites. \\
        Commitment & The algorithm guaranteeing sites to agree on the set and final order of all the operations. \\
    	\bottomrule
    \end{tabular}
    \caption{Common terms in eventual consistency.}
\end{table}

As mentioned earlier, the key of data replication is the fact that data is replicated across several computers. These computers are often called \textit{sites}. Sometimes master sites are distinguished from normal sites, where master sites have full read and write access, and normal sites are only allowed to read the replicated data. This replicated data, which is on each site, consists of multiple small components. These are known as \textit{replicas} of an \textit{object}. One can view an object as the minimal unit of a replication. While a replica is the copy of a particular object on a particular site. Logically, a site stores numerous replicas, but in order to not make it too complex, a replica often refers to all the replicas on a site. \\
\indent An eventual consistent application allows the users to access and update replicas synchronously. Such local updates performed on one of the replicas are called \textit{operations}. When describing algorithms, it is useful to distinguish systems who describe operations more semantically, called \textit{operation-transfer systems}, from \textit{state-transfer systems}, where operations are limited to overwrite the entire object. Actually the second system is like a degenerate form of the first system. Operation-transfer systems maintain a history, also known as a log, of all recent operations on each replica. From this history they agree on the set and final order of the eventual operations. This increases the flexibility of conflict resolution, as well as the efficiency when objects are large. Maintaining eventual consistency in state-transfer systems is much simpler because only the newest object needs to be kept. \\
\indent Operations in the log of a particular site, but not yet part of the absolute order of the eventual consistent system, are often called \textit{tentative operations}. The reason that these operations are tentative and not permanent, relates to the possibility of multiple users modifying the same object at the same time. This causes a \textit{conflict} to arise. One could simple ignore such situation, for instance an airplane ticket reservation system could handle two concurrent requests to the same seat by picking one and discarding the other. This was previously mentioned as 'lost-updates'. However, a better way to handle this problem is to detect conflicting operations, for example with vector clocks, subsequently resolving them. Resolving can be performed by the user or by automatic conflict resolution strategies. \\
\indent Eventually, operations stored in the log, needs to be sent to the other sites. This process is referred as \textit{propagation}. A common propagation technique is called epidemic propagation, which allows all sites to receive operations from each other even when they are not directly connected. More particular, sites propagate their own operations as well as the operations received from another site to their 'neighbors'. Operations spread like a virus, hence epidemic propagation. However, this technique can only be used when sites are directly connected with each other, which is usually not the case for offline available web applications. \\
\indent As previously mentioned, the sites needs to agree on the set and final order of all the operations and conflict resolution results. The algorithm guaranteeing this key concept is called \textit{commitment}. 

\section{Applications}\label{sec:Applications}

In previous sections, eventual consistency is described in general, making it rather abstract. The reason for this relates to the wide range of eventual consistent applications. Therefore, it is useful to discuss a few applications in which this concept can be used. \\
First, it is possible to distinguish three types of architectures used in these application: client EC, server EC and peer-to-peer EC. Where 'EC' stands for eventual consistency. In a client EC architecture, data on the server will be replicated among all the different clients. Thus the server plays the role of the master site while the clients are considered normal sites. This is shown in figure~\ref{fig:clientEC}, the server in the middle replicates the data to the clients on the outside. Note that a client is not necessarily a computer, but can be a mobile device as well. A key advantage of this architecture is the possibility for clients to modify and read data even when completely disconnected from the internet. However depending on the application, it is recommended to sporadically synchronize with the server to push and pull new updates in order that replicas do not differ too much from each other. \\
Server EC and peer-to-peer EC architectures will not be further discussed as the considered applications are based upon a client EC architecture. As the title of this paper presumes, the main focus in this paper are shared and offline available data for the web. This boils down to the implementation of offline available collaborative web applications. Properties of such collaborative applications is that they run in a web browser, and that it is still possible to use the functionalities, once disconnected from the internet. 

\begin{figure}
    \small
    \centering
    \includegraphics[scale=0.3]{clientEC.png}
    \caption{A client EC architecture.}
    \label{fig:clientEC}
\end{figure}

\subsection{Birdwatching}\label{subsec:Birdwatching}

The first application is a simple birdwatching tool. The main purpose of this application is to track the sort and amount of birds a single person or group has spotted. After users registered themselves, they can add birds. To add a bird, the user enters the name of the bird and the amount of times he has seen it. It is also possible to collaborate with multiple users on one single list of spotted birds. To share a list, the user hands out a unique token peculiar to every list. From now on, users who received the token, can enter the token to synchronize with the list to collaborate. After synchronization, all operations work seamlessly while offline. For example, two birdwatchers, Alice and Bob use the application to share the type and amount of birds they have seen. Alice is located in a place with intermittent internet connection, while Bob has no problems at all. However, Alice can still add birds, even without internet connection. Let say Alice presumed she has seen an eagle and adds it to the list. At the same time, Bob spotted three robins in his bird's nest at home, also adding it to the list. After synchronization by both users, the list shows one eagle and three robins. Now, the alleged eagle comes closer, and appears to be a falcon. Alice quickly deletes the eagle entry in the list, and adds a falcon. Meanwhile, Bob has spotted another eagle flying around his home. Now, when Alice regains connection, she should see one falcon, one eagle (The one Bob has seen) and three robins. If the application is poorly designed, the amount of eagles might be two instead of one, since at the moment Bob enters an eagle, he still assumes Alice has seen an eagle instead of a falcon, making the amount of eagles two. In a well designed eventually consistent application, these values will be added or subtracted, so the list will show only one eagle, one falcon and three robins.

\subsection{Version Control System}\label{subsec:VCS}

The second example is a Version Control System. The purpose of such a system is to manage documents, programs, websites, and other information data, by storing all the changes made in the data. This enables to track each change, and to reverse changes when necessary. These systems are essential for distributed and collaborative development. A few examples are Git\footnote{Git, \url{http://git-scm.com/}}, Mercurial\footnote{Mercurial, \url{http://mercurial.selenic.com/}} and Pixelapse\footnote{Pixelapse, \url{https://www.pixelapse.com/}}. Users can create their own repository. Every file in this repository will be tracked. Just as in the birdwatching example, problems might arise when used concurrently. If Alice and Bob are sharing a repository, they need to be able to modificate files at the same time. One solution is to make sure data can only be changed when connected to the server. So the server always checks if a constraint is not violated. But because the main purpose of this paper is offline available and collaborative web applications, offline availability is important. Yet, it is impossible to allow offline availability without the arise of conflicts considering the change of the same set of data. However a possible solution is to notify the users if they regain connection, in order to solve the conflict. 

\chapter{Preparatory Work}\label{cha:StateOfTheArt} % 5

While previous chapter introduced some of the key concepts and possible applications of eventual consistency, this chapter will focus on the current state of the art of eventual consistency. Although eventual consistency is not a new concept, in fact it has been around for more than 30 years, there seems to be a recent interest. This is mainly due to the rise of mobile devices with intermittent connection and the need for large scattered servers to ensure availability. Multiple systems and models, investigated and developed, will be discussed in order to extract the useful information to model a system for implementing offline available collaborative web applications. This system will be fully described in section~\ref{cha:CloudTypes}. \\

In 2000 Eric Brewer, a professor at the University of California, conceived the CAP conjecture. This conjecture asserts that distributed systems only have two of three desirable properties. These properties are consistency, availability and partition tolerance, hence the abbreviation 'CAP'. Two years later, in 2002, Gilbert and Lynch actually proved Brewer's conjecture, transforming it into a theorem.

\begin{description}
 \item[Consistency] \hfill \\In a consistent system, there is a guarantee that all nodes, at any time, share the same view of the data. In fact, this is the the key feature of pessimistic replication, discussed in section~\ref{sec:PessimisticReplication}.
 \item[Availability] \hfill \\This property implies that data is always available for reading or writing. This is mostly achieved by distributing the data over multiple servers, so that when a site crashes, the data is still available on other sites. (cf. section~\ref{sec:Elements})
 \item[Partition Tolerance] \hfill \\A partition tolerant application continues to work despite network failures. For example, When data is replicated over N sites, and for some reason there is no or intermittent connection among some sites. As a result, the nodes are unable to synchronize data, thus a part of the system does not work. Such partition causes the system to lose either consistency or availability.
\end{description}

Important to note is that instead of the fact that one must sacrifice a property for two other properties, it is interesting that one can sacrifice one of the properties. This makes the theorem of great importance, especially for eventual consistency, where the consistency property can be left out. The introduction of the CAP theorem led to a new wave of researchers, diverging from the ACID model. ACID consists of the properties availability, consistency, isolation and durability and provide a guarantee that distributed transactions are processed reliable. Thus, where consistency is obligatory in ACID, one is allowed to drop this property using the CAP theorem. This model, where availability and partition tolerance is chosen above consistency, is often called BASE (Basically Available, Soft state, Eventual consistency). \\
However, over the years it became clear that the "2 of 3" formulation was misleading. In fact, hybrid solutions were more common than applications strictly following the CAP formulation. Thus, about a decade later, Eric Brewer revised his theorem. The revision of his theorem described that distributed applications have to balance out consistency and availability in the presence of partitioning. In fact, the developer has to maximize combinations of consistency and availability that make sense for the kind of application. Additionally, he stated that this balancing can occur at different levels and even at particular operations in the system. Hence, this revision is a much more fine-grained description of the original theorem, confirming what everyone implicitly noticed in the beginning. 

\section{State of The Art}\label{sec:StateOfTheArt}

As mentioned previously, the introduction of the CAP theorem led to a new wave of researchers. These researchers have come up with numerous designs and models for the problems arising when one sacrifices consistency for availability. In this section, three models will be explained in more detail in order to extract useful information for the system that will be implemented. 

\subsection{NoSQL}\label{subsec:NoSQL}

Relational databases like SQL have been the primary model during the past decades, but when one needs to handle large volumes of data, these kind of databases are not well scalable. Therefore, while SQL is based on the ACID model, NoSQL takes a different approach by relying on the BASE model. In general, NoSQL are simple key-value stores without a predefined schema. In contrast to the tabular relations in SQL, this completely different model allows easy horizontal scalability (e.g. adding more nodes to a system instead of adding more resources to a single node) in order to cope with increasing data volumes and access. Despite the fact that it uses a different model, some SQL operations are still supported, hence it is also called 'not only SQL'. There are multiple types of NoSQL, which can be distinguished in four main categories. 

\begin{description}
 \item[Key-value Stores] \hfill \\This type is the most simple model and easy to implement. The main idea is that every item in the database consists of a key mapped to a particular value using hash tables. However it has some disadvantages, including the inefficiency of querying or updating only a part of a value. Examples of Key-value stores are Voldemort\footnote{Voldemort, \url{http://www.project-voldemort.com/}}, Dynamo\footnote{Dynamo, \url{http://aws.amazon.com/dynamodb/}} and Riak\footnote{Riak, \url{http://basho.com/riak/}}.
 \item[Wide Column Stores] \hfill \\Wide Column stores, often called extensible record stores, store data in key-value pairs with the ability to store a very large number of dynamic columns, i.e. values. Since the keys and the values are extensible, wide column stores can be seen as two-dimensional Key-value stores. Example of such stores are Google's BigTable\footnote{Google BigTable, \url{http://research.google.com/archive/bigtable.html}}, which is used for for most of Google's services, and Cassandra\footnote{Cassandra, \url{http://cassandra.apache.org/}}.
 \item[Document Databases] \hfill \\Document stores, also called document-oriented database systems, are described by a schema-less data organization. In fact, they can be seen as key-value stores on steroids. First, values can exist out of multiple columns, just like in wide column stores, called documents. secondly, these documents do not need to have a uniform structure. Finally, the nesting of documents is also supported. These documents often store internal notations like JSON or XML, which can be directly processed. Examples of these databases are MongoDB\footnote{MondoDB, \url{http://www.mongodb.org/}} and CouchDB\footnote{CouchDB, \url{http://couchdb.apache.org/}}.    
 \item[Graph Databases] \hfill \\Graph databases represent data in graph structures. These consist out of nodes, who are connected through edges. They are used to store everything related to graphs and processing of data specific to the graph (e.g. distance between two nodes). An example of this type is Neo4J\footnote{Neo4J, \url{http://neo4j.com/}}.    
\end{description}

In fact, NoSQL do not have the eventual consistency properties that will be used in this paper. The goal of NoSQL databases is to achieve availability on the server-side, by using horizontal scalability. Hence, NoSQL is focused on server EC (cf. section~\ref{sec:Applications}). The goal in this the model of this paper is client EC or replicating data to clients, in order to allow offline usage. However, NoSQL has to largest share in the eventual consistency community. 

\subsection{Bayou}\label{subsec:Bayou}

Bayou is a mobile distributed database allowing mobile users to use their applications offline. The database can be replicated across multiple sites, i.e. mobile devices or servers. Users on a mobile device, can use and modify the database while offline and thereafter synchronize with any other database that the he finds, when connected. Updates are done in SQL statements and propagated to other sites using epidemic propagation. Received updates are applied tentatively locally but because sites receives operation in different orders, thet have to undo and redo some operations while learning the total order of operations, determined by master sites. If a operation results in a conflict, it can be detected and resolved by an application-specific precondition and deterministic merge procedure defined by the developer, both connected to the operation. A major drawback though is that the system is entirely build on the requirement of epidemic propagation, which causes the inability to ensure strong consistency when necessary. As previously mentioned, the developer can write application-specific merge procedures to avoid conflicts, but this becomes quickly complicated. \\
Considering this, Bayou is an interesting model where the implementing system can be based upon. Although, it lacks a few important elements such as strong consistency on demand and predefined merge procedures which provide commutativity (cf. section~\ref{sec:Model}). 

\subsection{Commutative Replicated Data Types (CRDT)}\label{subsec:CRDT}

Up to now, the eventual consistency community consists of numerous specific problems and applications such as distributed text editing, distributed file system, NoSQL databases,\ldots  But so far, there are few attempts to bring eventual consistency closer to the programming language itself, with dedicated concepts and models from which various eventual consistent application can be developed. In fact, this is the purpose of Commutative Replicated Data Types, abbreviated by CRDT. These data types can be found on the program level, replicated over various instances of the program. The key factor of these data types is that their operations are commutative. This means that the replicated data will converge to a single value, even if operations on the same piece of data occurred concurrently. In other words, the operations do not conflict with each other. In a system without commutative operations, the system does not know in which order the operations must be executed. Also one of the sites where the operation came from, needs to reschedule the operation in order to be consistent with the other site by undoing and redoing operations. \\
\indent For example, two clients are executing operation \textit{x} and \textit{y} concurrently. If the total order will be \textit{xy}, client 2 has to undo \textit{y}, do \textit{x} and redo \textit{y}. If the total order will be \textit{yx}, client 1 has to undo \textit{x}, do \textit{y} and redo \textit{x}. However, if the system uses commutative operations, \textit{xy} and \textit{yx} produce the same state. \\
In fact, commutative operations leads to the superfluity of operation scheduling. An example of such operations in our daily lives is the addition. If two persons, i.e. clients, concurrently add some number to the same number, it does not matter in which order the additions occurred. \\
There are roughly three distinguishable types of CRDT. operation-based CRDT's communicate witch each other by interchanging isolated operations, while state-based CRDT's interchange whole states. Finally, delta CRDT's combines the features of the previous CRDT's. \\ 
\\
Although this is a good solution for some operations, this can not be used for all operations and applications. Take for example a key-value store where names are mapped on phone numbers. If two clients concurrently set the value of the same person, lost-updates will occur (cf. section~\ref{sec:OptimisticReplication}). There is no commutative solution for this problem. Yet, the model can be used to to reason about commutative operations in eventual consistent applications. As today, there are numerous of useful application where this concept already can be used. For example, Youtube views or Facebook likes. Riak (cf. section~\ref{subsec:NoSQL}) is also integrating CRDT concepts in their database system to ensure consistency at large scale for very low cost. 

\section{Model}\label{sec:Model}

After extracting some useful information from different eventual consistency models, it is time to find a programming model that could be suited to implement offline available collaborative web applications. This model must meet certain requirements, which are summarized below.

\begin{description}
 \item[Full-fledged Programming Model] \hfill \\The model should be a full-fledged programming model, in the sense that the developer can create his own distributed data and operations, resulting in a specific application. This generality can also be found in the CRDT model (cf. section~\ref{subsec:CRDT}). Distribution and synchronization of distributed data must be transparent for the developer.
 \item[Transparent Disconnected Operations] \hfill \\A second criteria is the transparency of disconnected operations. The developer should not be engaged with checking whether the client is online or offline while executing a specific operation. The model should keep a kind of log where executed operations are stored and automatically synchronized once the client regains connection. 
 \item[Commutativity] \hfill \\As mentioned previously, commutative operations leads to the disappearance of conflicts and the superfluity of operation scheduling while ensuring consistency at large scale. A model supporting this kind of operation would be a nice bonus.  
 \item[Strong consistency on demand] \hfill \\Sometimes strong consistency is essential in a distributed application. For example in a ticket reservation application, a user do not want to hear after the reservation that his reservation is eventually canceled. Thus, strong consistency on demand would increase the diversity of applications that could be realised with the model.
\end{description}

In order to take account of these requirements, Cloud Types seems to best solution to implement offline available collaborative web applications. Cloud types focuses on most of the above criteria. Although, it has some shortcomings for easily implementing the desired applications. The Cloud Types model will be discussed in detail in the following section.


\chapter{Cloud Types}\label{cha:CloudTypes} % 10

In previous sections the concept eventual consistency is explained along with several models and applications. This led to the agreement of using Cloud Types for developing offline available collaborative web applications. This section will give a more fine-grained explanation of these Cloud Types based on Sebastian Burckhardt's description.

\section{Introduction}\label{sec:Introduction}

The goal of Cloud Types is to make eventual consistency programming more convenient by providing eventual consistent storage at the programming level. This is achieved by the abstractation of several implementation details in an uniform language, in order to hide these complexities for the developer. Concretely, the developer can declare data using particular types, called \textit{cloud types}, which are automatically shared between the different devices. By bringing eventual consistency to the programming level, the amount of possible applications strongly increases. Clearly, the model solves different challenges that are daunting to implement in offline available collaborative web applications. The most common challenges are summarized below.

\begin{description}
 \item[Representation] \hfill \\Because web programming involves different communities, developers need to write and maintain huhge amounts of code between different data representations. For example, a simple web application connected to a database, needs to translate database representations (e.g. SQL) into server-side representations of the data types (e.g. Node.js). Subsequently, these data types need to be serialized for sending them to the client-side (e.g. JSON, XML). Finally, the developer needs to translate these data into HTML in order to display the appropriate data on the screen. In short, developers have to deal with different programming platform differences between databases, servers and clients. 
 \item[Eventual Consistency] \hfill \\This includes the different challenges of eventual consistency mentioned in previous sections. These are data replication and propagation, conflict resolution, consistency between the different clients,\ldots
 \item[Change Sets] \hfill \\If one wants to develop offline available collaborative web applications, storing just a local replica is not enough. Keeping a log of updates or a delta of the updates is necessary. When the client is reconnected, the log can be sent to the server so other clients can perform these updates.
\end{description}

Given these challenges, it is not surprising that apps almost no application has the requirements for the model. Hence, Cloud Types are introduced which ensures the transparency of these challenges for the developer, which allows him to focus on more application-specific data declarations and operations. The developer do not need to take into account several tasks like network communication, data synchronization and data presentation. The two main factors of this solution are:

\begin{description}
 \item[Cloud Types] \hfill \\The developer declares data, their wishing to share, using particular cloud types. This data is automatically replicated across all the clients and persisted both on local storage as well as in the cloud. the Cloud Types model includes two kinds of types. The first one, \textit{simple types}, mainly covers integers and strings. \textit{Structured types} provide more structured types as tables and indexes. These types will be further discussed in the execution model (cf. section~\ref{subsec:ExecutionModel}). These types share the property of remaining predictable when concurrency occurs. The conflict resolution is done automatically, which reduces the developer's amount of work for writing merging procedures to zero.
 \item[Revision Consistency] \hfill \\ The model uses \textit{revision diagrams} in order to make the different replicas converge, thus to ensure eventual consistency. This concept will be discussed in detail in the synchronization model (cf. section~\ref{subsec:SynchronizationModel}). In short, the cloud stores the main revision, while the clients store local revision. These local revision will however be periodically synchronized with the cloud. In fact, one can consider this technique as the concept of Version Control Systems (cf. section~\ref{subsec:VCS}) applied to Cloud Types. The cloud acts as the main revision while the clients maintain a local revision by \textit{forking} and \textit{joining} from the main revision.
\end{description} 

This approach considers all aspects of the data model, thus there is only one single program and data format. The data model is not a new language but rather an extension for many existing languages. Currently, the model is partial implemented in the TouchDevelop mobile development environment, which allows developers to create collaborative web applications by making use of a mobile IDE. Fascinating is that although the servers maintain consistency, the developer does not write any code peculiar to the server. The different data declarations determine the processes on the server. 

\section{Core Principles}\label{sec:CorePrinciples}

This section introduces the Cloud Types model in more detail on the basis of an example in pseudocode using a typed javascript-like language. This explanation is divided into two main parts. The first part, the execution model, handles the main concepts of Cloud Types along with the fundamental functionalities. The synchronization model focuses on the different synchronization mechanisms in order to guarantee eventual consistency.

%figure hack to make the minipage float
\begin{figure}
\begin{minipage}[t]{\textwidth}
\vspace{-3cm}
\input{birdwatching.tex}
\end{minipage}
\end{figure}

\subsection{Execution Model}\label{subsec:ExecutionModel}

Remember the birdwatching tool as explained in section~\ref{subsec:Birdwatching}. This application allows users to track the sort and amount of birds they spotted individually or in group. The code for this application is given in Listing~\ref{lst:birdwatching}. Note that the authorization part is left out because unnecessary to explain the model. \\
\\
First, consider the top of the code excerption, where the cloud data is declared. The data is called \textit{cloud} data because they remain in the cloud. Basically, this means that the data is automatically replicated across all the clients of a peculiar list in the birdwatching tool. In fact, it is very similar to declaring global variables in other languages. Some deviation from the original version are made. Firstly, the application is also tracking the total amount of birds spotted, independently from the type of bird. Secondly, the birdwatchers' names will be stored in a special table. These adaptations will be helpful to clarify some concepts further on. Thus, the application is storing three elements:

\begin{enumerate}
 \item To store the total amount of birds spotted, the variable \textbf{totalBirds} is declared. Note that the type of this variable is a \textcolor{codedarkblue}{CInt}, Where 'C' stands for cloud and 'Int' for integer. A cloud integer differs from a normal integer in the sense that it offers operations taking care of conflict resolution instead of the normal getter and setter. One of these operations is \textbf{add}, which is an example of the earlier defined commutative operations. Add expresses a relative rather than a absolute change to a number.
 \item For storing the amount of a particular bird, a special data type \textcolor{codeblue}{Index} is used. Although this type is not prefixed with 'C', it is one of the two main cloud stores. This index \textbf{BirdList} is indexed by the name of the bird. Each entry in the index stores a cloud integer \textbf{amountSpotted}, holding the amount of specific birds are spotted. 
 \item The names of all the birdwatchers is kept in a \textcolor{codeblue}{Table}. This data type is, just as the index, a collection to store cloud data. Each entry in the table \textbf{BirdWatcher} stores a \textcolor{codedarkblue}{CString} with the name of a birdwatcher. However, the difference with an index is the possibility to dynamically create and delete entries.
\end{enumerate}

Before moving to the operations on the cloud data in the example, it is important to take a closer look to the cloud stores mentioned above. In the Cloud Types model there are two distinct cloud store constructs. The first one is \textcolor{codedarkblue}{Table}, which is used to store the birdwatchers' names. The second construct is \textcolor{codedarkblue}{Index}, which is used to maintain the amount of birds. Both types have the property that the data they store is shared between all the clients automatically. Thus, they are able to change the values locally and synchronize eventually with the other clients. \\ 

A \textcolor{codeblue}{Table} is similar to a relational database table. As mentioned previously, one can dynamically create and delete entries in the table, what distinguishes it from a index construct. Thus, it has extensible rows, where each row has optionally keys and a number of columns. While the keys are fixed and need to be defined at creation time of the table, the columns values are variable in time. The keys of a table can consist of any type. It can be a normal primitive type like \textcolor{codedarkblue}{Int} and \textcolor{codedarkblue}{Boolean}, or one of the cloud stores, \textcolor{codeblue}{Table} and \textcolor{codeblue}{Index}. On the other hand, a column must be a cloud type like \textcolor{codedarkblue}{CString} and \textcolor{codedarkblue}{CInt}. In fact, the keys act as construction arguments or immutable fields and moreover possess a pleasant side-effect. When one of the keys of a table is another table, a deletion of an entry in the key table causes the deletion of all the entries in the main table depending on this deleted entry. \\

To illustrate the power that comes with \textcolor{codeblue}{Index}, one must try to use a table for storing the \textbf{BirdList}. It seems perfectly possible to use a table \textbf{BirdList} with the name of the bird as key, and the \textbf{amountSpotted} cloud integer as column. Each row will represent the number of times a particular bird is spotted. To add a new bird, it is essential to look that this entry does not yet exist. If this is not the case, creating a new entry is allowed. Although this looks flawlessly, there is one considerable problem. Suppose two birdwatchers are offline, while spotting the same bird. if the bird is not yet in the table, they will both create a new entry. After synchronization, two rows of the same bird will exists because the keys of the table do not have to be unique. Obviously, these two entries need to be merged with each other. The solution for this problem is to use an \textcolor{codeblue}{Index}. In this type of collection, entries can not be created or deleted. Consequently, one would wonder how to store data in this kind of collection. Surprisingly, all the entries already exist 'virtually'. An \textcolor{codeblue}{Index} is like an infinite hash map between the index and the different values of this index, the columns. Important to note is that each these values is initialized with a default value depending on the type (e.g. the default value for \textcolor{codedarkblue}{CInt} is 0). \\
Looking back to the example, \textbf{BirdList} virtually stores the spotted-amount of all existing birds in the universe. Technically, equal birds will resolve to the same entry and birds with a default value will not be stored physically. \\




\subsection{Synchronization Model}\label{subsec:SynchronizationModel}

\chapter{Conclusion}\label{cha:Conclusion} % 1





\end{document}

%Bibliografie:

%cs.metrostate.edu/~fitzgesu/courses/ics662/spring10/Notes/SaitoSummary.htm
%http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed
%https://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf
%http://ivoroshilin.com/2012/12/13/brewers-cap-theorem-explained-base-versus-acid/
%http://db-engines.com/en/article/Wide+Column+Stores
%http://rebelic.nl/2011/05/28/the-four-categories-of-nosql-databases/
%http://db-engines.com/en/article/Document+Stores
%http://db-engines.com/en/article/Graph+DBMS
%http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.7323
%http://pagesperso-systeme.lip6.fr/Marc.Shapiro/papers/RR-6956.pdf