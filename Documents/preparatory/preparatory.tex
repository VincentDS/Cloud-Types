\documentclass[a4paper,12pt]{report}

% The following makes latex use nicer postscript fonts.
\usepackage{times}
\usepackage[english]{babel}
%\usepackage[colorlinks,urlcolor=blue,linkcolor=blue]{hyperref}
\usepackage[grey,utopia]{quotchap}
\usepackage{booktabs}
\usepackage{vubtitlepage}


\author{Vincent De Schutter}
\title{Preparatory: Automagically shared and \\offline available data for the web}

%\promotortitle{Promotor/Promotors}
\promotor{Prof. Dr. Wolfgang De Meuter}
\advisors{Tim Coppieters}
\advisortitle{Begeleider}
\faculty{Faculteit Wetenschappen en Bio-ingenieurswetenschappen}
\department{Vakgroep Computerwetenschappen}
\reason{Voorbereiding voor Proefschrift ingediend met het oog op het behalen \\van de graad van 
Bachelor of Science in de computerwetenschappen}
\date{Februari 2015}
          
\begin{document}

% First dutch TitlePage
\maketitlepage

\faculty{Faculty of Science and Bio-Engineering Sciences}
\advisortitle{Advisor}
\department{Department of Computer Science}
\reason{Preparatory to Bachelor Thesis submitted in partial fulfillment of the \\
requirements for the degree of Bachelor of Science in Computer Science}

\date{February 2015}

% Then english TitlePage
\maketitlepage

\tableofcontents
\newpage

\chapter{Introduction} % 1
%TODO
\chapter{Context} % 5

%TODO
This chapter includes an introduction to the main concepts of eventual consistency. 

\section{Eventual Consistency} 

One of the most important aspects of distributed systems is data replication. This phenomenon is used in a wide range of applications, such as databases, caches, and many more. In this case, data replication will consists out of maintaining multiple copies of data on different computers. Those copies, often called replicas, improve the availablilty, performance and safety of the distributed system. \\
When one of the replicas is offline, availability is achieved by allowing access to the data through another replica. This also offers applications to work offline, which is one of the key subjects of this paper. \\
If the data is replicated across multiple computers, also called sites, the user can reduce the latency by choosing the nearest site. Besides that, different requests can be handled concurrently which reduces the load on a specific site. \\
Another benefit of data replication is safety. If replicas are considered as backups, safety is attained. For example, when one of the replicas experiences a deadly crash, the data is not lost because it can still be aqcuired from another site.\\
\newline
When talking about data replication, there are roughly two types to distinguish. The first one is called traditional or pessimistic replication. This is a more strong technique that focusses on consistent data at the expense of availability. If the data needs to be more available but may differ a little, optimistic replication is a better solution.

\subsection{Pessimistic Replication}

The main purpose of pessimistic replication is trying to maintain one single consistent state of the data on all the different sites. This can be achieved by allowing updates to a specific piece of data only when it is consistent with all other replications. If some data is not up to date, it will be locked until it's consistent. Hence the name "pessimistic". This technique is also known as strong consistency due the fact that there is only one single view of the data and therefore all the replicas are consistent. Pessimistic replication is used in a wide range of applications and algorithms. For example, primary-copy algorithms, elect a primary replica that is responsible for handling all access to a specific object. If the primary replica receives an update of this object, it will be propagated synchronously to all secondary replicas. In case the primary replica crashes, the other replicas agree to assign another primary replica. A drawback of this technique is the deployment on a wide-area network for two reasons. \\
\indent First, replicas could be unavailable for too long due the slowness en unreliability of the Internet. This causes even more problems with the raise of mobile devices with intermittent connectivity. Synchronizing with an unavailable replica, would block the device indefinitely. \\
\indent The second reason relates to scalability towards wide-area networks. Applications with pessimistic replication on larger networks often have more users and replicas. The more users, the more updates will occur, the more time the replicas need to wait to send the updates to the other replicas. \\
Because of this two reasons pessimistic replication is mainly used in local-area applications. A major part uses optimistic replication instead.

\subsection{Optimistic Replication}

When replicated data needs to be shared efficiently in a wide-area network, optimistic replication is a preferable solution. The key difference between optimistic and pessimistic replication is the possibility to access and update replicas synchronously without locking the data. However this feature gives rise to new conflicts. If a piece of data isn't locked, two or more operations can concurrently adjust the piece of data. This leads to inconsistent data and thus inconsistent replicas. The optimistic part of this algorithm is the assumption that these concurrent operations occur sporadically or will be easy to resolve. However, the impact of the concurrent operations depends on the application. \\
\indent For example, when two users perform an operation on the same piece of date independently. The first user updates the data while the seconds user removes the data. Will the data been removed or been updated when the two operations are merged? The first one, often called 'lost-updates', causes the first user to lose his updates. The second possibility will undo the removal of the second user. This won't seem that complicated, however what will happen if three or more users perform an operation on the same piece of data? \\
It is the role of consistency models to ensure that all the replicas, who have the possibility to temporarily differ from each other, converge to one single consistent state. Thus the replicas will be eventual consistent. Hence, optimistic replication is often referred as eventual consistency. Due the high availability of eventual consistent applications, the data can be, without first synchronizing, accessed and updated concurrently. This feature makes it possible to work with an unreliable or even without a connection. \\

\subsection{Elements of Eventual Consistency}

When talking about eventual consistency, there are a few important basic concepts one needs to know. These terms are also widely used throughout this paper and the actual paper about eventual consistency. 
\newline

\begin{table}
    \small
	\centering
    \begin{tabular}{l|p{9,5cm}}
    	\toprule
   		Term & Meaning \\
    	\midrule
    	Site & A single computer which stores a copy of replicated data in a replicated system is called a site. \\
    	Object & A notion of the minimal data unit in a replicated system. \\
    	Replica & A copy of a particular object on a particular site. \\
        Operation & A local update performed on one of the replicas. \\
        Tentative operation & Local operations that are not yet part of the final order of the system. \\
        Operation-transfer & Eventual consistency system where operations are described more semantically. \\
        State-transfer & Eventual consistency system where operations are limited to overwrite entire objects. \\
        Log & A list of recent operations stored on each site. \\
        Conflict & The phenomen when multiple users perform concurrent updates to the same object. \\
        Propagation & The process responsible for sending operations to the other sites. \\
        Commitment & The algorithm guaranteeing sites to agree on the set and final order of all the operations. \\
    	\bottomrule
    \end{tabular}
    \caption{Common terms in eventual consistency.}
\end{table}

As mentioned earlier, the key of data replication is the fact that data is replicated across several computers. These computers are often called \textit{sites}. Sometimes master sites are distinguished from normal sites, where master sites have full read and write access, and normal sites are only allowed to read the replicated data. This replicated data, which is on each site, consists of multiple small components. These are known as \textit{replicas} of an \textit{object}. One can view an object as the minimal unit of a replication. While a replica is the copy of a particular object on a particular site. Logically, a site stores numerous replicas, but in order to not make it too complex, a replica often refers to all the replicas on a site. \\
\indent An eventual consistent application allows the users to access and update replicas synchronously. Such local updates performed on one of the replicas are called \textit{operations}. When describing algorithms, it is useful to distinguish systems who describe operations more semantically, called \textit{operation-transfer systems}, from \textit{state-transfer systems}, where operations are limited to overwrite the entire object. Actually the second system is like a degenerate form of the first system. Operation-transfer systems maintain a history, also known as a log, of all recent operations on each replica. From this history they agree on the set and final order of the eventual operations. This increases the flexibilty of conflict resolution, as well as the efficiency when objects are large. Maintaining eventual consistency in state-transfer systems is much simpler because only the newest object needs to be kept. \\
\indent Operations in the log of a particular site, but not yet part of the absolute order of the eventual consistent system, are often called \textit{tentative operations}. The reason that these operations are tentative and not permanent, relates to the possibility of multiple users modifying the same object at the same time. This causes a \textit{conflict} to arise. One could simple ignore such situation, for instance an airplane ticket reservation system could handle two concurrent requests to the same seat by picking one and discarding the other. This was previously mentioned as 'lost-updates'. However, a better way to handle this problem is to detect conflicting operations, for example with vector clocks, subsequently resolving them. Resolving can be performed by the user or by automatic conflict resolution strategies. \\
\indent Eventually, operations stored in the log, needs to be sent to the other sites. This process is referred as \textit{propagation}. A common propagation technique is called epidemic propagation, which allows all sites to receive operations from each other even when they are not directly connected. More particular, sites propagate their own operations as well as the operations received from another site to their 'neighbours'. Operations spread like a virus, hence epidemic propagation. However, this technique can only be used when sites are directly connected with each other, which is usually not the case for offline available we applications. \\
\indent As previously mentioned, the sites needs to agree on the set and final order of all the operations and conflict resolution results. The algorithm guaranteeing this key concept is called \textit{commitment}. 

\section{Applications}

In previous sections, eventual consistency is described in general, making it rather abstract. The reason for this relates to the wide range of eventual consistent applications. Therefore, it is useful to discuss a few applications in which this concept can be used. \\
First, it is possible to distinguish three types of architectures used in these application: client EC, server EC and peer-to-peer EC. Where 'EC' stands for eventual consistency. In a client EC architecture, data on the server will be replicated among all the different clients. Thus the server plays the role of the master site while the clients are considered normal sites. This is shown in figure~\ref{fig:clientEC}, the server in the middle replicates the data to the clients on the outside. Note that a client is not necessarily a computer, but can be a mobile device as well. A key advantage of this architecture is the possibility for clients to modify and read data even when completely disconnected from the internet. However depending on the application, it is recommended to sporadically synchronize with the server to push and pull new updates in order that replicas do not differ too much from each other. \\
Server EC and peer-to-peer EC architectures will not be further discussed as the considered applications are based upon a client EC architecture. As the title of this paper presumes, the main focus in this paper are shared and offline available data for the web. This boils down to the implementation of offline available collaborative web applications. Properties of such collaborative applications is that they run in a web browser, and that it is still possible to use the functionalities, once disconnected from the internet. 

\begin{figure}
    \small
    \centering
    \includegraphics[scale=0.3]{clientEC.png}
    \caption{A client EC architecture.}
    \label{fig:clientEC}
\end{figure}

\subsection{Birdwatching}

The first application is a simple birdwatching tool. The main purpose of this application is to track the sort and amount of birds a single person or group has spotted. After users registered themselves, they can add birds. To add a bird, the user enters the name of the bird and the amount of times he has seen it. It is also possible to collaborate with multiple users on one single list of spotted birds. To share a list, the users hands out a unique token peculiar to every list. 

\chapter{State-of-the-art} % 5
\chapter{Cloud Types} % 10
\chapter{Conclusion} % 1





\end{document}

%Bibliografie:

%cs.metrostate.edu/~fitzgesu/courses/ics662/spring10/Notes/SaitoSummary.htm
